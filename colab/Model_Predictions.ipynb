{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgrifka/nfl_motion_coverage_overlap/blob/main/colab/Model_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcudYBV7exbz"
      },
      "source": [
        "# **Model Predictions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4be5GEse2aN"
      },
      "source": [
        "We're going to use the neural net that we trained in the `Model Training.ipynb` file to predict overlap intensity during pre-snap motion.\n",
        "\n",
        "Much of the data preparation code is similar to the code in `Model Training.ipynb`, so if you have questions, then I suggest you start there first (https://github.com/dgrifka/nfl_motion_coverage_overlap)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUmky4cFx1Tq"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/dgrifka/nfl_motion_coverage_overlap.git\n",
        "\n",
        "import os\n",
        "\n",
        "# Change this to the path of your repository\n",
        "repo_path = '/content/nfl_motion_coverage_overlap'\n",
        "os.chdir(repo_path)\n",
        "\n",
        "# Import the necessary functions\n",
        "%run setup.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6conBtO14BW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCgLm8-o1_Wi"
      },
      "outputs": [],
      "source": [
        "players = read_nfl_csv('players')\n",
        "games = read_nfl_csv('games')\n",
        "plays_raw = read_nfl_csv('plays')\n",
        "# Add team names and features, such as offense score differential\n",
        "plays = process_nfl_plays(plays_raw, games)\n",
        "player_play = read_nfl_csv('player_play')\n",
        "\n",
        "# For pre-snap data\n",
        "pre_snap = process_tracking_data(\n",
        "    tracking_path=google_drive_path,\n",
        "    snap_type=\"pre\",\n",
        "    weeks=range(1, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMO9PQCw2Q48"
      },
      "outputs": [],
      "source": [
        "# For post-snap data\n",
        "pre_snap_total = merge_tracking_data(pre_snap, plays, players, add_team_column)\n",
        "pre_snap_total_normalized = normalize_direction(pre_snap_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzE6k3Ai3I98"
      },
      "outputs": [],
      "source": [
        "ball_df = get_initial_ball_position(pre_snap_total_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZMniTKoFKcT"
      },
      "outputs": [],
      "source": [
        "# If you'd only like to train on a few games, then reduce the number below\n",
        "n_games = 1000\n",
        "# Get unique game IDs\n",
        "game_ids = pre_snap_total_normalized.select('gameId').unique().head(n_games)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp7wgepn2S0A"
      },
      "outputs": [],
      "source": [
        "# Get defensive players\n",
        "def_presnap_df = filter_players_by_position(pre_snap_total_normalized, game_ids, 'defense')\n",
        "\n",
        "# Get offensive players\n",
        "off_presnap_df = filter_players_by_position(pre_snap_total_normalized, game_ids, 'offense')\n",
        "\n",
        "# Add distance_from_football feature\n",
        "def_presnap_df_with_distance = add_distance_from_football(def_presnap_df, ball_df)\n",
        "\n",
        "# Add distance_from_football feature\n",
        "off_presnap_df_with_distance = add_distance_from_football(off_presnap_df, ball_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BkNPud9fgZ4"
      },
      "source": [
        "In order to use/load the model we created previously, we need to define a function in this Colab file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c82Qzuii1gpF"
      },
      "outputs": [],
      "source": [
        "def load_model_and_scalers(model_name, base_path='model/actual_models'):\n",
        "    \"\"\"\n",
        "    Load a saved model and its scalers from individual files.\n",
        "\n",
        "    Parameters:\n",
        "        model_name (str): Name of the model ('offensive' or 'defensive')\n",
        "        base_path (str): Base path where model files are stored\n",
        "    \"\"\"\n",
        "    # Register the custom loss function\n",
        "    tf.keras.utils.get_custom_objects()['route_aware_loss'] = route_aware_loss\n",
        "\n",
        "    # Enable unsafe deserialization\n",
        "    tf.keras.config.enable_unsafe_deserialization()\n",
        "\n",
        "    # Construct full file paths\n",
        "    model_path = os.path.join(base_path, f'{model_name}_model.keras')\n",
        "    scalers_path = os.path.join(base_path, f'{model_name}_scalers.pkl')\n",
        "    history_path = os.path.join(base_path, f'{model_name}_history.pkl')\n",
        "\n",
        "    # Check if files exist\n",
        "    for filepath in [model_path, scalers_path, history_path]:\n",
        "        if not os.path.exists(filepath):\n",
        "            raise FileNotFoundError(f\"Could not find file: {filepath}\")\n",
        "\n",
        "    # Load the model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Load the scalers\n",
        "    with open(scalers_path, 'rb') as f:\n",
        "        scalers = pickle.load(f)\n",
        "\n",
        "    # Load the history\n",
        "    with open(history_path, 'rb') as f:\n",
        "        history = pickle.load(f)\n",
        "\n",
        "    return (\n",
        "        model,\n",
        "        (scalers['position_scaler'], scalers['context_scaler']),\n",
        "        scalers['y_scaler'],\n",
        "        history\n",
        "    )\n",
        "\n",
        "# Load offensive model and scalers\n",
        "off_model, off_scaler_X, off_scaler_y, off_history = load_model_and_scalers('offensive')\n",
        "# Load defensive model and scalers\n",
        "def_model, def_scaler_X, def_scaler_y, def_history = load_model_and_scalers('defensive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kegnqmpafn_B"
      },
      "source": [
        "Next, we're going to randomly sample plays where the defense was in \"Man\" and \"Zone\". Then, we're going to make overlap predictions for each play based on the pre-snap movement and save them as a csv, which we'll then upload to GitHub for future analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMVsuK9h92gh"
      },
      "outputs": [],
      "source": [
        "# Make sure we're not duplicating analysis\n",
        "existing_manzone = pd.read_csv('model/zone_man_overlap.csv')\n",
        "existing_manzone.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7ZtBdQ3TGeA"
      },
      "outputs": [],
      "source": [
        "# Sample of Man and Zone plays\n",
        "sampled_plays = sample_man_zone_plays(off_presnap_df_with_distance, n_samples=6)\n",
        "sampled_plays = filter_sampled_plays(existing_manzone, sampled_plays)\n",
        "\n",
        "man_df = None\n",
        "zone_df = None\n",
        "\n",
        "# Loop through Man plays\n",
        "print(\"Processing Man coverage plays...\")\n",
        "for game_id, play_id in tqdm(sampled_plays['man_plays'], desc='Man Plays'):\n",
        "    # Create animation and get metrics\n",
        "    man_overlap_df = create_route_overlap_animation(\n",
        "        off_presnap_df_with_distance,\n",
        "        def_presnap_df_with_distance,\n",
        "        off_model,\n",
        "        def_model,\n",
        "        off_scaler_X,\n",
        "        def_scaler_X,\n",
        "        off_scaler_y,\n",
        "        def_scaler_y,\n",
        "        game_id=game_id,\n",
        "        play_id=play_id,\n",
        "        fps=4\n",
        "    )\n",
        "    man_overlap_df['pff_manZone'] = 'Man'\n",
        "\n",
        "    if man_df is None:\n",
        "        man_df = man_overlap_df\n",
        "    else:\n",
        "        man_df = pd.concat([man_df, man_overlap_df])\n",
        "\n",
        "# Loop through Zone plays\n",
        "print(\"\\nProcessing Zone coverage plays...\")\n",
        "for game_id, play_id in tqdm(sampled_plays['zone_plays'], desc='Zone Plays'):\n",
        "    # Create animation and get metrics\n",
        "    zone_overlap_df = create_route_overlap_animation(\n",
        "        off_presnap_df_with_distance,\n",
        "        def_presnap_df_with_distance,\n",
        "        off_model,\n",
        "        def_model,\n",
        "        off_scaler_X,\n",
        "        def_scaler_X,\n",
        "        off_scaler_y,\n",
        "        def_scaler_y,\n",
        "        game_id=game_id,\n",
        "        play_id=play_id,\n",
        "        fps=4\n",
        "    )\n",
        "    zone_overlap_df['pff_manZone'] = 'Zone'\n",
        "\n",
        "    if zone_df is None:\n",
        "        zone_df = zone_overlap_df\n",
        "    else:\n",
        "        zone_df = pd.concat([zone_df, zone_overlap_df])\n",
        "\n",
        "# Concat zone_df and man_df\n",
        "zone_man = pd.concat([zone_df, man_df])\n",
        "zone_man.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download csv\n",
        "from google.colab import files\n",
        "zone_man.to_csv('zone_man_overlap_new.csv', index=False)\n",
        "files.download('zone_man_overlap_new.csv')\n",
        "\n",
        "# Concat new zone_man to the bottom of existing_manzone\n",
        "existing_manzone = pd.concat([existing_manzone, zone_man])\n",
        "existing_manzone.to_csv('zone_man_overlap.csv', index=False)\n",
        "files.download('zone_man_overlap.csv')"
      ],
      "metadata": {
        "id": "KP5I9rhdVZex"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOORJwgZ7Jmoz2MqhT+60sl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}